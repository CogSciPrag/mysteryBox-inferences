---
title: "Myster box inferences: LLM results"
author: "PT&MF"
date: "2023-12-16"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(tidyboot)
library(cspplot)
```

# Overview

We explore the performance of text-davinci-003 and all Llama-2 models (both base and chat) on experiments 1-3 from Degano et al 2024, experiments 1-2 from Marty et al 2023 and experiments 4-6 from Marty et al 2022. All practice trials are used as a few-shot prompt (i.e. correct solutions were presented).

The results were retrieved by retrieving the log probability of the labels "good" / "bad" following the prompt. The selected answer is identified by selecting the max probability. For simplicity, the prompts are linked here:

* [Degano et al 2024](https://github.com/CogSciPrag/mysteryBox-inferences/blob/main/data/prompts/Deganoetal2024_instructions.txt)
* [Marty et al 2023](https://github.com/CogSciPrag/mysteryBox-inferences/blob/main/data/prompts/Martyetal2023_instructions.txt)
* [Marty et al 2022](https://github.com/CogSciPrag/mysteryBox-inferences/blob/main/data/prompts/Martyetal2022_instructions.txt)

```{r data, warning=FALSE, message=FALSE, echo=FALSE}
results_paths_degano2024 <- list.files(path = "../../results/01_raw/", pattern = "Deganoetal2024_*",
           full.names = TRUE) 
results_paths_marty2023 <- list.files(path = "../../results/01_raw/", pattern = "Martyetal2023_*",
           full.names = TRUE) 
results_paths_marty2022 <- list.files(path = "../../results/01_raw/", pattern = "Martyetal2022_*",
           full.names = TRUE) 


# read files and save model name
read_and_save_model <- function(p) {
  d <- read_csv(p)
  d <- d %>% mutate(model = str_split(p, "_", simplify=T)[,5])
  return(d)
}
read_and_save_model_zs <- function(p) {
  d <- read_csv(p)
  d <- d %>% mutate(model = str_split(p, "_", simplify=T)[,6])
  return(d)
}
read_and_save_model_q <- function(p) {
  d <- read_csv(p)
  d <- d %>% mutate(model = str_split(p, "_", simplify=T)[,7])
  return(d)
}
degano2024 <- bind_rows(map(results_paths_degano2024, read_and_save_model)) #%>% filter(model != "Mistral-7B-Instruct-v0.2")
marty2023 <- bind_rows(map(results_paths_marty2023, read_and_save_model)) #%>% filter(model != "Mistral-7B-Instruct-v0.2")
marty2022 <- bind_rows(map(results_paths_marty2022, read_and_save_model)) #%>% filter(model != "Mistral-7B-Instruct-v0.2")

```

# Analysis

Below we analyse the selected response. We apply two analyses: 

* WTA: first, we compute the proportion of responses predicting that the trigger sentence is "good" by checking whether the "good" response was assigned the higher LLH / probability (trial-level).
* item-level probability: we compute the probability assigned to each response by applying softmax (alpha = 1) to LLHs from each trial and then averaging over the response probabilities by condition.

In our other studies, thw WTA approach has shown better fit to human data. However, based on plots below, the probability based analysis might be better for these datasets.

```{r preprocess}
process_response <- function(d) {
d <- d %>% 
  rowwise() %>%
  mutate(
    chosen_response_llh = max(Mean_logprob_answer_good, Mean_logprob_answer_bad),
    chosen_response = ifelse(chosen_response_llh == Mean_logprob_answer_good, "Mean_logprob_answer_good", "Mean_logprob_answer_bad"),
    chosen_response = str_split(chosen_response, "_", simplify=T)[,4],
    norm_factor = sum(exp(Mean_logprob_answer_good), exp(Mean_logprob_answer_bad)),
    prob_good = exp(Mean_logprob_answer_good) / norm_factor,
    prob_bad = exp(Mean_logprob_answer_bad) / norm_factor
  )
  return(d)
}
```

We apply these analyses by-study and then group the respective stats by conditions of each respective study.
```{r}
degano2024_processed <- process_response(degano2024)
marty2023_processed <- process_response(marty2023)
marty2022_processed <- process_response(marty2022)

degano2024_acc_rate <- degano2024_processed %>% 
  mutate(
    is_good = as.numeric(chosen_response == "good")
  ) %>% 
  group_by(model, Condition, Experiment) %>% 
  tidyboot_mean(column = is_good)
degano2024_acc_rate

marty2023_acc_rate <- marty2023_processed %>% 
  mutate(
    is_good = as.numeric(chosen_response == "good")
  ) %>% 
  group_by(model, Quantifier_type, Condition, Experiment) %>% 
  tidyboot_mean(column = is_good)
marty2023_acc_rate

marty2022_acc_rate <- marty2022_processed %>%
  mutate(
    is_good = as.numeric(chosen_response == "good")
  ) %>% 
  group_by(model, Negation, Polarity, Inference_type, Condition, Experiment) %>% 
  tidyboot_mean(column = is_good)
marty2022_acc_rate
```

The processed data is saved such that the probabilities of each response option as well as the selected response are included on top of the raw materials' csvs (**columns prob_good, prob_bad, chosen_response** are the new columns containing the model results), along with the information which model was used to produce the results. The columns "prob_good", "prob_bad" contain trial-level probability of each option, while "chosen_response" contains the chosen response based on the argmax over prob_good and prob_bad (i.e., WTA strategy). 
```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
#degano2024_processed %>%
#  select(-Few_shot_items_order, -Mean_logprob_answer_good, -Mean_logprob_answer_bad, -Sentence_logprob_answer_good, -Sentence_logprob_answer_bad, -chosen_response_llh, -norm_factor) %>%
#  write_csv("../results/02_tidy/Deganoetal2024_results_tidy.csv")
#marty2023_processed %>%
#  select(-Few_shot_items_order, -Mean_logprob_answer_good, -Mean_logprob_answer_bad, -Sentence_logprob_answer_good, -Sentence_logprob_answer_bad, -chosen_response_llh, -norm_factor) %>%
#  write_csv("../results/02_tidy/Martyetal2023_results_tidy.csv")
#marty2022_processed %>%
#  select(-Few_shot_items_order, -Mean_logprob_answer_good, -Mean_logprob_answer_bad, -Sentence_logprob_answer_good, -Sentence_logprob_answer_bad, -chosen_response_llh, -norm_factor) %>%
#  write_csv("../results/02_tidy/Martyetal2022_results_tidy.csv")
```

# Exploratory accuracy analysis

To determine which linking function (WTA or item-level probability averaging) is better, we explore the accuracy on the control conditions (bad and good in all experiments), by single experiment. For exploration, we also check the control performance by-condition, where relevant.

```{r}
check_controls <- function(d, return_all=FALSE) {
  if("Deganoetal_2024" %in% d$Study){
    d_controls <- d %>% filter(Sentence_type != "Test")
  } else if("Martyetal_2023" %in% d$Study){
    d_controls <- d %>% filter(Sentence_type != "Test")
  } else {
    d_controls <- d %>% filter(Condition != "Target")
  }
  d_controls_props <- d_controls  %>%
    mutate(ground_truth = ifelse(Condition == "Good", "good", "bad"),
         is_correct = ground_truth == chosen_response,
         option_probability = ifelse(Condition == "Good", prob_good, prob_bad))
  
  d_summary <- d_controls_props %>%
    group_by(Study, Experiment, model) %>%
  summarize(wta_accuracy = mean(is_correct),
            item_prob_accuracy = mean(option_probability)) %>%
  mutate(better_metric = ifelse(wta_accuracy > item_prob_accuracy, "wta_accuracy", "item_prob_accuracy"))
  
  # sort to models according to acc
  expts <- d_summary %>% pull(Experiment) %>% unique()
  if (return_all){
    top3 <- d_summary %>%
      arrange(desc(wta_accuracy))
  } else {
  top3 <- tibble()
  for (i in expts){
    top_3_for_e <- d_summary %>%
      filter(Experiment == i) %>%
      arrange(desc(wta_accuracy)) %>%
      filter(wta_accuracy > 0.55) %>%
      slice(1:3)
    top3 <- rbind(top3, top_3_for_e)
  }
  }

return(top3)
}

best_models_degano <- check_controls(degano2024_processed) # %>%ungroup()%>% count(better_metric)
best_models_marty2023 <- check_controls(marty2023_processed)  #%>%ungroup()%>% count(better_metric)
best_models_marty2022 <- check_controls(marty2022_processed) #%>%ungroup()%>% count(better_metric)
```

```{r}
# write control accuracy for the paper
conrol_acc_degano <- check_controls(degano2024_processed, return_all = TRUE) 
conrol_acc_marty2023 <- check_controls(marty2023_processed, return_all = TRUE) 
conrol_acc_marty2022 <- check_controls(marty2022_processed, return_all = TRUE) 
#conrol_acc_degano %>% select(-item_prob_accuracy, -better_metric) %>% write_csv("../../results/02_processed_all/degano2024_control_acc.csv")
#conrol_acc_marty2023 %>% select(-item_prob_accuracy, -better_metric) %>% write_csv("../../results/02_processed_all/marty2023_control_acc.csv")
#conrol_acc_marty2022 %>% select(-item_prob_accuracy, -better_metric) %>% write_csv("../../results/02_processed_all/marty2022_control_acc.csv")
```

Create a wide table of controll accuracies:
```{r}
controls_all <- rbind(conrol_acc_degano, conrol_acc_marty2023, conrol_acc_marty2022)
controls_all_wide <- controls_all %>% select(-item_prob_accuracy, -better_metric) %>%
  mutate(wta_accuracy = round(wta_accuracy, 2)) %>%
  pivot_wider(names_from = c(Study, Experiment), names_sep = "_", values_from = wta_accuracy)

#controls_all_wide %>% write_csv("../../results/02_processed_all/control_acc_all.csv")
```

Based on the analyses above, the following turns out: For all studies, across experiments, WTA is a better linking function in terms of control accuracy by-study by-experiment. I.e., under WTA, average control accuracies of experiments were higher. We select top 3 models for each experiment based on WTA. In particular, we only take models whose performance is above chance at least by 0.05 (i.e., at least 0.56).

* Degano et al 2024: 
  * E1: top 3 models: text-davinci-003, Llama-2-70b-hf, Llama-2-13b-hf
  * E2: top 3 models: Llama-2-7b-hf, Llama-2-13b-hf, 	Llama-2-70b-hf
  * E3: top 3 models: text-davinci-003, Llama-2-70b-hf, Llama-2-13b-hf (Mixtral instead of 13b)
* Marty et al 2023: 
  * E1: top 3 models: text-davinci-003, Llama-2-70b-hf,	Llama-2-7b-chat-hf or Llama-2-13b-hf (tie) (Mixtral and Mistral-7B-v0.1 instead of 13b and 7b)
  * E2: top 3 models: text-davinci-003, Llama-2-70b-hf, Llama-2-13b-hf (Mixtral instead of 13b)
* Marty et al 2022: 
  * E4: top 3 models: text-davinci-003, Llama-2-70b-hf (and mixtral)
  * E5: top 3 models: text-davinci-003, Llama-2-70b-hf (and mixtral)
  * E6: top 3 models: text-davinci-003, Llama-2-70b-hf,	Llama-2-7b-chat-hf
  
Therefore, we subset the data to these results only. The tidy data frames can be found under results/03_tidy. The also only contain WTA predictions now. 
```{r, echo=FALSE}
degano_filtered <- degano2024_processed %>%
  filter(( (model == "text-davinci-003")) | 
           ((model == "Llama-2-70b-hf")) |
           ((model == "Llama-2-13b-hf")) 
           ) %>% select(-norm_factor, -prob_good, -prob_bad, -chosen_response_llh)
#degano_filtered %>% write_csv("../../results/03_tidy/deganoetal2024_tidy.csv")

marty2023_filtered <- marty2023_processed %>%
  filter(
           ((Experiment == "Exp_1") & (model == "Mistral-7B-v0.1")) |
          ((Experiment == "Exp_2") & (model == "text-davinci-003")) |
           ((model == "Mixtral-8x7B-v0.1")) |
           ((model == "Llama-2-70b-hf"))
           ) %>% select(-norm_factor, -prob_good, -prob_bad, -chosen_response_llh)

#marty2023_filtered %>% write_csv("../../results/03_tidy/martyetal2023_tidy.csv")

marty2022_filtered <- marty2022_processed %>%
  filter(((Experiment == "Exp_4") & (model == "Llama-2-70b-hf")) | 
           ((Experiment == "Exp_4") & (model == "Mixtral-8x7B-v0.1")) | 
          ((Experiment == "Exp_5") & (model == "Mistral-7B-Instruct-v0.2")) | 
           ((Experiment == "Exp_5") & (model == "Mixtral-8x7B-Instruct-v0.1")) |
           ((Experiment == "Exp_6") & (model == "Llama-2-70b-hf")) | 
           ((Experiment == "Exp_6") & (model == "Llama-2-7b-chat-hf")) |
           ((model == "text-davinci-003"))  
           ) %>% select(-norm_factor, -prob_good, -prob_bad, -chosen_response_llh)
#marty2022_filtered %>% write_csv("../../results/03_tidy/martyetal2022_tidy.csv")
```

# Plots
Below, we plot the mean acceptance rate (i.e., the mean proportion of judgments that a trigger sentence is good) by-model, by experiment and by-condition. 

### WTA approach

Plot for Degano et al 2024:
```{r, fig.height=10}
degano2024_acc_rate %>% 
  ggplot(., aes(x = Condition, y = mean, ymin = ci_lower, ymax = ci_upper)) +
  geom_col() +
  geom_errorbar(width = 0.1) +
  facet_wrap(model~Experiment, ncol = 3) +
  ylab("Acceptance rate") +
  theme_csp() +
  theme(axis.text.x = element_text(angle=30)) 
```

Marty et al 2023: 
```{r, fig.height=10}
marty2023_acc_rate %>% 
  ggplot(., aes(x = Condition, y = mean, fill = Quantifier_type, ymin = ci_lower, ymax = ci_upper)) +
  geom_col(position = position_dodge()) +
  geom_errorbar(position = position_dodge(0.95), width = 0.1) +
  facet_wrap(model~Experiment) +
  ylab("Acceptance rate") +
  theme_csp() +
  theme(axis.text.x = element_text(angle=30)) 
```

Marty et al 2022: 
```{r, fig.height=20}
# by experiment
e4 <- marty2022_acc_rate %>% 
  filter(Experiment == "Exp_4") %>%
  ggplot(., aes(x = Condition, y = mean, fill = Polarity, ymin = ci_lower, ymax = ci_upper)) +
  geom_col(position = position_dodge()) +
  geom_errorbar(position = position_dodge(0.95), width = 0.1) +
  facet_wrap(Inference_type~model, nrow = 4) +
  ylab("Acceptance rate") +
  theme_csp() +
  theme(axis.text.x = element_text(angle=30)) 

e5 <- marty2022_acc_rate %>% 
  filter(Experiment == "Exp_5") %>%
  ggplot(., aes(x = Condition, y = mean, fill = Polarity, ymin = ci_lower, ymax = ci_upper)) +
  geom_col(position = position_dodge()) +
  geom_errorbar(position = position_dodge(0.95), width = 0.1) +
  facet_wrap(Inference_type~model, nrow = 4) +
  ylab("Acceptance rate") +
  theme_csp() +
  theme(axis.text.x = element_text(angle=30))

e6 <- marty2022_acc_rate %>% 
  filter(Experiment == "Exp_6") %>%
  ggplot(., aes(x = Condition, y = mean, fill = Polarity, ymin = ci_lower, ymax = ci_upper)) +
  geom_col(position = position_dodge()) +
  geom_errorbar(position = position_dodge(0.95), width = 0.1) +
  facet_wrap(Inference_type~model, nrow = 4) +
  ylab("Acceptance rate") +
  theme_csp() +
  theme(axis.text.x = element_text(angle=30)) 

# bind the plots together
gridExtra::grid.arrange(e4, e5, e6)
```

### Average probability

Now the same plots are replicated with the average probability assigned to the "acceptance" (i.e., "good") response.
```{r, warning=FALSE, message=FALSE, echo=FALSE}
degano2024_prob <- degano2024_processed %>% 
  group_by(model, Experiment, Condition) %>% 
  tidyboot_mean(column = prob_good)
degano2024_prob

marty2023_prob <- marty2023_processed %>% 
  group_by(model, Quantifier_type, Condition, Experiment) %>% 
  tidyboot_mean(column = prob_good)
marty2023_prob

marty2022_prob <- marty2022_processed %>%
  group_by(model, Negation, Polarity, Inference_type, Condition, Experiment) %>% 
  tidyboot_mean(column = prob_good)
marty2022_prob
```

```{r, warning=FALSE, fig.height=10}
degano2024_prob %>% 
  ggplot(., aes(x = Condition, y = mean, ymin = ci_lower, ymax = ci_upper)) +
  geom_col() +
  geom_errorbar(width = 0.1) +
  facet_wrap(Experiment~model) +
  ylab("Probability of acceptance") +
  theme_csp() +
  theme(axis.text.x = element_text(angle=30)) 
```
```{r, warning=FALSE, fig.height=10}
marty2023_prob %>% 
  ggplot(., aes(x = Condition, y = mean, fill = Quantifier_type, ymin = ci_lower, ymax = ci_upper)) +
  geom_col(position = position_dodge()) +
  geom_errorbar(position = position_dodge(0.95), width = 0.1) +
  facet_wrap(Experiment~model) +
  ylab("Probability of acceptance") +
  theme_csp() +
  theme(axis.text.x = element_text(angle=30)) 
```
```{r, warning=FALSE, fig.height=20}
e4_prob <- marty2022_prob %>% 
  filter(Experiment == "Exp_4") %>%
  ggplot(., aes(x = Condition, y = mean, fill = Polarity, ymin = ci_lower, ymax = ci_upper)) +
  geom_col(position = position_dodge()) +
  geom_errorbar(position = position_dodge(0.95), width = 0.1) +
  facet_wrap(Inference_type~model, nrow = 4) +
  ylab("Probability of acceptance") +
  theme_csp() +
  theme(axis.text.x = element_text(angle=30)) 

e5_prob <- marty2022_prob %>% 
  filter(Experiment == "Exp_5") %>%
  ggplot(., aes(x = Condition, y = mean, fill = Polarity, ymin = ci_lower, ymax = ci_upper)) +
  geom_col(position = position_dodge()) +
  geom_errorbar(position = position_dodge(0.95), width = 0.1) +
  facet_wrap(Inference_type~model, nrow = 4) +
  ylab("Probability of acceptance") +
  theme_csp() +
  theme(axis.text.x = element_text(angle=30)) 

e6_prob <- marty2022_prob %>% 
  filter(Experiment == "Exp_6") %>%
  ggplot(., aes(x = Condition, y = mean, fill = Polarity, ymin = ci_lower, ymax = ci_upper)) +
  geom_col(position = position_dodge()) +
  geom_errorbar(position = position_dodge(0.95), width = 0.1) +
  facet_wrap(Inference_type~model, nrow = 4) +
  ylab("Probability of acceptance") +
  theme_csp() +
  theme(axis.text.x = element_text(angle=30)) 

# bind the plots together
gridExtra::grid.arrange(e4_prob, e5_prob, e6_prob)
```

# Explore 0-shot results

An exploration of zero-shot results was also conducted (with Llama 2 7b base, 7b chat, 13b base and 13b chat). The WTA results and trial-level probability results are shown below.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
zero_shot_degano2024 <- list.files(path = "../results/00_exploration/", pattern = "Deganoetal2024_*",
           full.names = TRUE)
zero_shot_marty2023 <- list.files(path = "../results/00_exploration/", pattern = "Martyetal2023_*",
           full.names = TRUE)
zero_shot_marty2022 <- list.files(path = "../results/00_exploration/", pattern = "Martyetal2022_*",
           full.names = TRUE)

zero_shot_degano <- bind_rows(map(zero_shot_degano2024, read_and_save_model_zs))
zero_shot_marty2023 <- bind_rows(map(zero_shot_marty2023, read_and_save_model_zs))
zero_shot_marty2022 <- bind_rows(map(zero_shot_marty2022, read_and_save_model_zs))

zero_shot_degano_processed <- process_response(zero_shot_degano)
zero_shot_marty2023_processed <- process_response(zero_shot_marty2023)
zero_shot_marty2022_processed <- process_response(zero_shot_marty2022)


# process (WTA and item level probability)
zero_shot_degano_acc_rate <- zero_shot_degano_processed %>% 
  mutate(
    is_good = as.numeric(chosen_response == "good")
  ) %>% 
  group_by(model, Condition, Experiment) %>% 
  tidyboot_mean(column = is_good)

zero_shot_marty2023_acc_rate <- zero_shot_marty2023_processed %>% 
  mutate(
    is_good = as.numeric(chosen_response == "good")
  ) %>% 
  group_by(model, Quantifier_type, Condition, Experiment) %>% 
  tidyboot_mean(column = is_good)

zero_shot_marty2022_acc_rate <- zero_shot_marty2022_processed %>%
  mutate(
    is_good = as.numeric(chosen_response == "good")
  ) %>% 
  group_by(model, Negation, Polarity, Inference_type, Condition, Experiment) %>% 
  tidyboot_mean(column = is_good)

zero_shot_degano_prob <- zero_shot_degano_processed %>% 
  group_by(model, Experiment, Condition) %>% 
  tidyboot_mean(column = prob_good)

zero_shot_marty2023_prob <- zero_shot_marty2023_processed %>% 
  group_by(model, Quantifier_type, Condition, Experiment) %>% 
  tidyboot_mean(column = prob_good)

zero_shot_marty2022_prob <- zero_shot_marty2022_processed %>%
  group_by(model, Negation, Polarity, Inference_type, Condition, Experiment) %>% 
  tidyboot_mean(column = prob_good)

```

For Degano et al 2024, as an example for direct comparison, put together zero-shot with few-shot results:
```{r}
zero_shot_acc_rate_prompts <- zero_shot_degano_acc_rate %>% 
  mutate(prompting = "zero-shot") %>%
  rbind(., 
        degano2024_acc_rate %>% 
          #filter(model == "Llama-2-13b-chat-hf") %>%
  mutate(prompting = "few-shot"))

zero_shot_prob_prompts <- zero_shot_degano_prob %>% 
  mutate(prompting = "zero-shot") %>%
  rbind(., 
        degano2024_prob %>% 
          #filter(model == "Llama-2-13b-chat-hf") %>%
  mutate(prompting = "few-shot"))
```

Average probability:
```{r, warning=FALSE, fig.height=8}
zero_shot_prob_prompts %>% 
  ggplot(., aes(x = Condition, y = mean, ymin = ci_lower, ymax = ci_upper, fill = prompting)) +
  geom_col(position=position_dodge()) +
  geom_errorbar(width = 0.1, position = position_dodge(0.95)) +
  facet_wrap(Experiment~model) +
  ylab("Probability of acceptance") +
  theme_csp() +
  theme(axis.text.x = element_text(angle=30)) 
```

WTA:
```{r, warning=FALSE, fig.height=8}
zero_shot_acc_rate_prompts %>% 
  ggplot(., aes(x = Condition, y = mean, ymin = ci_lower, ymax = ci_upper, fill = prompting)) +
  geom_col(position=position_dodge()) +
  geom_errorbar(width = 0.1, position = position_dodge(0.95)) +
  facet_wrap(Experiment~model) +
  ylab("Acceptance rate") +
  theme_csp() +
  theme(axis.text.x = element_text(angle=30)) 
```

Now we replicate the overview plots from above on the zero-shot data.
WTA:
```{r, message=FALSE, warning=FALSE, echo=FALSE, fig.height=8}
zero_shot_degano_acc_rate %>% 
  ggplot(., aes(x = Condition, y = mean, ymin = ci_lower, ymax = ci_upper)) +
  geom_col() +
  geom_errorbar(width = 0.1) +
  facet_wrap(model~Experiment, ncol = 3) +
  ylab("Acceptance rate") +
  theme_csp() +
  theme(axis.text.x = element_text(angle=30)) 
```
```{r, message=FALSE, warning=FALSE, echo=FALSE, fig.height=8}
zero_shot_marty2023_acc_rate %>% 
  ggplot(., aes(x = Condition, y = mean, fill = Quantifier_type, ymin = ci_lower, ymax = ci_upper)) +
  geom_col(position = position_dodge()) +
  geom_errorbar(position = position_dodge(0.95), width = 0.1) +
  facet_wrap(model~Experiment) +
  ylab("Acceptance rate") +
  theme_csp() +
  theme(axis.text.x = element_text(angle=30)) 
```
```{r, message=FALSE, warning=FALSE, echo=FALSE, fig.height=20}
# by experiment
e4_zs <- zero_shot_marty2022_acc_rate %>% 
  filter(Experiment == "Exp_4") %>%
  ggplot(., aes(x = Condition, y = mean, fill = Polarity, ymin = ci_lower, ymax = ci_upper)) +
  geom_col(position = position_dodge()) +
  geom_errorbar(position = position_dodge(0.95), width = 0.1) +
  facet_wrap(Inference_type~model, nrow = 4) +
  ylab("Acceptance rate") +
  theme_csp() +
  theme(axis.text.x = element_text(angle=30)) 

e5_zs <- zero_shot_marty2022_acc_rate %>% 
  filter(Experiment == "Exp_5") %>%
  ggplot(., aes(x = Condition, y = mean, fill = Polarity, ymin = ci_lower, ymax = ci_upper)) +
  geom_col(position = position_dodge()) +
  geom_errorbar(position = position_dodge(0.95), width = 0.1) +
  facet_wrap(Inference_type~model, nrow = 4) +
  ylab("Acceptance rate") +
  theme_csp() +
  theme(axis.text.x = element_text(angle=30))

e6_zs <- zero_shot_marty2022_acc_rate %>% 
  filter(Experiment == "Exp_6") %>%
  ggplot(., aes(x = Condition, y = mean, fill = Polarity, ymin = ci_lower, ymax = ci_upper)) +
  geom_col(position = position_dodge()) +
  geom_errorbar(position = position_dodge(0.95), width = 0.1) +
  facet_wrap(Inference_type~model, nrow = 4) +
  ylab("Acceptance rate") +
  theme_csp() +
  theme(axis.text.x = element_text(angle=30)) 

# bind the plots together
gridExtra::grid.arrange(e4_zs, e5_zs, e6_zs)

```

Item-level probability (wide-scope):

```{r, message=FALSE, warning=FALSE, echo=FALSE, fig.height=8}
zero_shot_degano_prob %>% 
  ggplot(., aes(x = Condition, y = mean, ymin = ci_lower, ymax = ci_upper)) +
  geom_col() +
  geom_errorbar(width = 0.1) +
  facet_wrap(model~Experiment, ncol = 3) +
  ylab("Probability of acceptance") +
  theme_csp() +
  theme(axis.text.x = element_text(angle=30)) 
```
```{r, message=FALSE, warning=FALSE, echo=FALSE, fig.height=8}
zero_shot_marty2023_prob %>% 
  ggplot(., aes(x = Condition, y = mean, fill = Quantifier_type, ymin = ci_lower, ymax = ci_upper)) +
  geom_col(position = position_dodge()) +
  geom_errorbar(position = position_dodge(0.95), width = 0.1) +
  facet_wrap(model~Experiment) +
  ylab("Probability of acceptance") +
  theme_csp() +
  theme(axis.text.x = element_text(angle=30)) 
```
```{r, message=FALSE, warning=FALSE, echo=FALSE, fig.height=20}
# by experiment
e4_zs <- zero_shot_marty2022_prob %>% 
  filter(Experiment == "Exp_4") %>%
  ggplot(., aes(x = Condition, y = mean, fill = Polarity, ymin = ci_lower, ymax = ci_upper)) +
  geom_col(position = position_dodge()) +
  geom_errorbar(position = position_dodge(0.95), width = 0.1) +
  facet_wrap(Inference_type~model, nrow = 4) +
  ylab("Probability of acceptance") +
  theme_csp() +
  theme(axis.text.x = element_text(angle=30)) 

e5_zs <- zero_shot_marty2022_prob %>% 
  filter(Experiment == "Exp_5") %>%
  ggplot(., aes(x = Condition, y = mean, fill = Polarity, ymin = ci_lower, ymax = ci_upper)) +
  geom_col(position = position_dodge()) +
  geom_errorbar(position = position_dodge(0.95), width = 0.1) +
  facet_wrap(Inference_type~model, nrow = 4) +
  ylab("Probability of acceptance") +
  theme_csp() +
  theme(axis.text.x = element_text(angle=30))

e6_zs <- zero_shot_marty2022_prob %>% 
  filter(Experiment == "Exp_6") %>%
  ggplot(., aes(x = Condition, y = mean, fill = Polarity, ymin = ci_lower, ymax = ci_upper)) +
  geom_col(position = position_dodge()) +
  geom_errorbar(position = position_dodge(0.95), width = 0.1) +
  facet_wrap(Inference_type~model, nrow = 4) +
  ylab("Probability of acceptance") +
  theme_csp() +
  theme(axis.text.x = element_text(angle=30)) 

# bind the plots together
gridExtra::grid.arrange(e4_zs, e5_zs, e6_zs)
```

# Quotation marks around answer options

For exploration purposes, we test whether performance changes (in a zero-shot setting), for 7b and 13b models, when the choice options appear as "good" or as "bad". Exploration is done on Degano et al 2024 only. 

```{r, echo=FALSE, message=FALSE, warning=FALSE}
degano_quotes_paths <- list.files(path = "../results/00_exploration/", pattern = "quotations_zeroShot_Deganoetal2024_*",
           full.names = TRUE) 
q_degano <- bind_rows(map(degano_quotes_paths, read_and_save_model_q))
q_degano_processed <- process_response(q_degano)
q_degano_processed_acc_rate <- q_degano_processed %>% 
  mutate(
    is_good = as.numeric(chosen_response == "good")
  ) %>% 
  group_by(model, Condition, Experiment) %>% 
  tidyboot_mean(column = is_good) 

q_degano_processed_prob <- q_degano_processed %>% 
  group_by(model, Experiment, Condition) %>% 
  tidyboot_mean(column = prob_good)


q_comparison <- q_degano_processed_acc_rate %>%
  mutate(prompt = "with quotes") %>%
  rbind(.,
zero_shot_degano_acc_rate %>% mutate(
  prompt = "no quotes"
))

q_comaprison_prob <- q_degano_processed_prob %>%
  mutate(prompt = "with quotes") %>%
  rbind(.,
zero_shot_degano_prob %>% mutate(
  prompt = "no quotes"
))
```

```{r, echo=FALSE, fig.height=15}
# WTA
q_comparison %>% 
  ggplot(., aes(x = Condition, y = mean, ymin = ci_lower, ymax = ci_upper, fill = prompt)) +
  geom_col(position=position_dodge()) +
  geom_errorbar(width = 0.1, position = position_dodge(0.95)) +
  facet_wrap(Experiment~model) +
  ylab("Acceptance rate") +
  theme_csp() +
  theme(axis.text.x = element_text(angle=30)) 

# probs 
q_comaprison_prob %>% 
  ggplot(., aes(x = Condition, y = mean, ymin = ci_lower, ymax = ci_upper, fill = prompt)) +
  geom_col(position=position_dodge()) +
  geom_errorbar(width = 0.1, position = position_dodge(0.95)) +
  facet_wrap(Experiment~model) +
  ylab("Probability of acceptance") +
  theme_csp() +
  theme(axis.text.x = element_text(angle=30))
```

# Exploration of control performance of other models

```{r}
results_paths <- c("../../results/01_raw/Deganoetal2024_Exp_1_Mistral-7B-Instruct-v0.2_20240116_0835.csv",
                   "../../results/01_raw/Deganoetal2024_Exp_1_Mistral-7B-v0.1_20240116_1047.csv",
                   "../../results/01_raw/Deganoetal2024_Exp_1_Mixtral-8x7B-Instruct-v0.1_20240116_1335.csv",
                   "../../results/01_raw/Deganoetal2024_Exp_1_pythia-6.9b_20240115_1723.csv",
                   "../../results/01_raw/Deganoetal2024_Exp_2_Mistral-7B-Instruct-v0.2_20240116_0836.csv",
                   "../../results/01_raw/Deganoetal2024_Exp_2_Mistral-7B-v0.1_20240116_1050.csv",
                   "../../results/01_raw/Deganoetal2024_Exp_2_Mixtral-8x7B-Instruct-v0.1_20240116_1348.csv",
                   "../../results/01_raw/Deganoetal2024_Exp_2_pythia-6.9b_20240115_1724.csv",
                   "../../results/01_raw/Deganoetal2024_Exp_3_Mistral-7B-Instruct-v0.2_20240116_0836.csv",
                   "../../results/01_raw/Deganoetal2024_Exp_3_Mistral-7B-v0.1_20240116_1050.csv",
                   "../../results/01_raw/Deganoetal2024_Exp_3_Mixtral-8x7B-Instruct-v0.1_20240116_1350.csv",
                   "../../results/01_raw/Deganoetal2024_Exp_3_pythia-6.9b_20240115_1724.csv"
                   )

model_results <- bind_rows(map(results_paths, read_and_save_model))

# check accuracy on control items
model_results %>% process_response(.) %>% check_controls()
```